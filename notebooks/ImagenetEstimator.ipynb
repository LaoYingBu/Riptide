{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "#from riptide.models.cifar_resnet import cifar_resnet20_v1\n",
    "#from riptide.binary.q_cifar_resnet import cifar_resnet20_v1\n",
    "from riptide.models.resnetv1b import resnet18_v1b\n",
    "from riptide.binary.HWGQ_funcs import Quantize, HWGQuantize, load_clusters, load_bits\n",
    "from riptide.binary.HWGQ_layers import Config\n",
    "from slim.preprocessing.inception_preprocessing import preprocess_image\n",
    "from riptide.utils.datasets import imagerecord_dataset\n",
    "from functools import partial\n",
    "from official.resnet import resnet_run_loop\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "nproc = multiprocessing.cpu_count()\n",
    "\n",
    "train_preprocess = partial(preprocess_image, height=224, width=224, is_training=True)\n",
    "def train_input_fn():\n",
    "    return imagerecord_dataset(batch_size, is_training=True, preprocess=train_preprocess, num_workers=nproc)\n",
    "\n",
    "val_preprocess = partial(preprocess_image, height=224, width=224, is_training=False)\n",
    "\n",
    "def eval_input_fn():\n",
    "    return imagerecord_dataset(batch_size, is_training=False, preprocess=val_preprocess, num_workers=nproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    #clusters = tf.constant(load_clusters(2))\n",
    "    #actQ = HWGQuantize\n",
    "    #weightQ = Quantize\n",
    "    #config = Config(actQ=actQ, weightQ=weightQ, clusters=clusters)\n",
    "    #with config:\n",
    "    #    model = ()\n",
    "    # Generate summary for the input images.\n",
    "    tf.summary.image('images', features, max_outputs=6)\n",
    "    model = resnet18_v1b()\n",
    "    logits = model(features)\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    cross_entropy = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Add weight decay\n",
    "    weight_decay = 1e-4\n",
    "    def exclude_batch_norm(name):\n",
    "        return 'batch_normalization' not in name\n",
    "    l2_loss = weight_decay * tf.add_n(\n",
    "        # loss is computed using fp32 for numerical stability.\n",
    "        [tf.nn.l2_loss(tf.cast(v, tf.float32)) for v in tf.trainable_variables()\n",
    "        if exclude_batch_norm(v.name)])\n",
    "    loss = cross_entropy + l2_loss \n",
    "    \n",
    "    # Log the model loss\n",
    "    #tf.identity(cross_entropy, name='cross_entropy')\n",
    "    #tf.identity(l2_loss, name='l2_loss')\n",
    "    tf.summary.scalar('l2_loss', l2_loss)\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "\n",
    "    # Create metrics for training accuracy.\n",
    "    accuracy = tf.metrics.accuracy(labels, predictions['classes'])\n",
    "    accuracy_top_5 = tf.metrics.mean(tf.nn.in_top_k(predictions=logits,\n",
    "                                                    targets=tf.reshape(labels, [-1]),\n",
    "                                                    k=5,\n",
    "                                                    name='top_5_op'))\n",
    "    metrics = {'accuracy': accuracy,\n",
    "               'accuracy_top_5': accuracy_top_5}\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        #optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        #lr = tf.train.exponential_decay(0.01, tf.train.get_global_step(), 20000, 0.1)\n",
    "        global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "        learning_rate_fn = resnet_run_loop.learning_rate_with_decay(\n",
    "            batch_size=batch_size, batch_denom=256, num_images=1281167,\n",
    "            boundary_epochs=[30, 60, 80, 90], decay_rates=[1, 0.1, 0.01, 0.001, 1e-4],\n",
    "            warmup=True, base_lr=.128)\n",
    "        learning_rate = learning_rate_fn(global_step)\n",
    "        # Create learning rate tensor for logging.\n",
    "        #tf.identity(learning_rate, name='learning_rate')\n",
    "        tf.summary.scalar('learning_rate', learning_rate)\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate = learning_rate, momentum=0.9)\n",
    "        #optimizer = tf.train.AdamOptimizer(learning_rate = lr)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=global_step)                \n",
    "\n",
    "        # Create a tensor named train_accuracy for logging purposes\n",
    "        #tf.identity(accuracy[1], name='train_accuracy')\n",
    "        #tf.identity(accuracy_top_5[1], name='train_accuracy_top_5')\n",
    "        tf.summary.scalar('train_accuracy', accuracy[1])\n",
    "        tf.summary.scalar('train_accuracy_top_5', accuracy_top_5[1])\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op, eval_metric_ops=metrics)\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 3600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f788747f050>, '_model_dir': '/data/jwfromm/models/resnet18_run3', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 2000, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 500, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1030 23:04:04.706338 140155764057920 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 3600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f788747f050>, '_model_dir': '/data/jwfromm/models/resnet18_run3', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 2000, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 500, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "#strategy = tf.contrib.distribute.MirroredStrategy(num_gpus=3)\n",
    "#run_config = tf.estimator.RunConfig(train_distribute=strategy)\n",
    "# Set up runconfig to do less logging for hopefully better performance.\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    save_summary_steps=2000, \n",
    "    log_step_count_steps=500, \n",
    "    save_checkpoints_secs=3600)\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, \n",
    "    model_dir=\"/data/jwfromm/models/resnet18_run3\",\n",
    "    config=run_config)\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=None)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1030 23:04:05.109523 140155764057920 tf_logging.py:115] Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 3600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1030 23:04:05.116319 140155764057920 tf_logging.py:115] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 3600.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1030 23:04:05.319539 140155764057920 tf_logging.py:115] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1030 23:04:08.903088 140155764057920 tf_logging.py:115] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1030 23:04:08.907370 140155764057920 tf_logging.py:115] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1030 23:04:09.830441 140155764057920 tf_logging.py:115] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1030 23:04:10.973629 140155764057920 tf_logging.py:115] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1030 23:04:11.016076 140155764057920 tf_logging.py:115] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /data/jwfromm/models/resnet18_run3/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1030 23:04:12.906497 140155764057920 tf_logging.py:115] Saving checkpoints for 0 into /data/jwfromm/models/resnet18_run3/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.155327, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1030 23:04:19.934381 140155764057920 tf_logging.py:115] loss = 7.155327, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.49608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1030 23:07:40.248045 140155764057920 tf_logging.py:115] global_step/sec: 2.49608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 7.147593, step = 500 (200.317 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1030 23:07:40.251480 140155764057920 tf_logging.py:115] loss = 7.147593, step = 500 (200.317 sec)\n"
     ]
    }
   ],
   "source": [
    "tf.estimator.train_and_evaluate(mnist_classifier, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
