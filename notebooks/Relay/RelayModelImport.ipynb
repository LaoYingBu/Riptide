{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwfromm/anaconda3/envs/octoml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jwfromm/anaconda3/envs/octoml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jwfromm/anaconda3/envs/octoml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jwfromm/anaconda3/envs/octoml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jwfromm/anaconda3/envs/octoml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jwfromm/anaconda3/envs/octoml/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jwfromm/anaconda3/envs/octoml/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jwfromm/anaconda3/envs/octoml/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jwfromm/anaconda3/envs/octoml/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jwfromm/anaconda3/envs/octoml/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jwfromm/anaconda3/envs/octoml/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jwfromm/anaconda3/envs/octoml/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tvm\n",
    "import tvm.relay as relay\n",
    "import tvm.contrib.graph_runtime as runtime\n",
    "from tvm.relay.expr_functor import ExprMutator\n",
    "from tvm.contrib import util\n",
    "from tvm.contrib.util import tempdir\n",
    "import riptide.models\n",
    "from riptide.get_models import get_model\n",
    "from tvm import autotvm\n",
    "from riptide.binary.binary_layers import Config, DQuantize, XQuantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(actQ=DQuantize, weightQ=XQuantize, bits=1, use_act=False, use_bn=False, use_maxpool=True)\n",
    "#config = Config(actQ=None, weightQ=None, bits=None, use_act=True, use_bn=True, use_maxpool=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jwfromm/anaconda3/envs/octoml/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "with config:\n",
    "    model = get_model('squeezenet')\n",
    "#model = riptide.models.vggnet_normal.vggnet()\n",
    "#model = tf.keras.models.Sequential(model.layers[:30])\n",
    "#model = tf.keras.models.Sequential()\n",
    "#model.add(tf.keras.layers.Conv2D(filters=96, strides=2, padding='same', kernel_size=7, use_bias=False, data_format='channels_last'))\n",
    "#model.add(tf.keras.layers.BatchNormalization(center=False, scale=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jwfromm/Riptide/riptide/binary/binary_layers.py:536: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "test_input = tf.keras.Input(shape=[224, 224, 3], batch_size=1, dtype='float32')\n",
    "output = model(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_ops = 0\n",
    "glue_ops = 0\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if 'conv2d' in layer.name:\n",
    "        _, h, w, f = layer.output_shape\n",
    "        k, _, c, _ = layer.weights[0].shape\n",
    "        #print(\"conv: \", k*k*h*w*f*c)\n",
    "        #print(\"glue: \", 14*h*w*f)\n",
    "        #print(\"ratio: \", k*k*c / 14)\n",
    "        conv_ops += k*k*h*w*f*c\n",
    "        glue_ops += 14 * h*w*f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786057216\n",
      "51806720\n",
      "15.172881355932203\n"
     ]
    }
   ],
   "source": [
    "print(conv_ops)\n",
    "print(glue_ops)\n",
    "print(conv_ops.value / glue_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod, params = relay.frontend.from_keras(model, shape={'input_1': [1, 224, 224, 3]}, layout='NHWC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = relay.transform.Sequential([relay.transform.FoldConstant(),\n",
    "                                  relay.transform.EliminateCommonSubexpr()])\n",
    "                                  #relay.transform.FuseOps(fuse_opt_level=2)])\n",
    "mod = seq(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tvm.target.arm_cpu(\"rasp3b\")\n",
    "target_host = 'llvm -device=arm_cpu -target=arm-linux-gnueabihf -mattr=+neon'\n",
    "#target=\"llvm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('conv2d_nhwc_spatial_pack.arm_cpu', ('TENSOR', (1, 227, 227, 3), 'float32'), ('TENSOR', (7, 7, 3, 96), 'float32'), (4, 4), (0, 0, 0, 0), (1, 1), 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('dense_nopack.x86', ('TENSOR', (1, 512), 'float32'), ('TENSOR', (1000, 512), 'float32'), None, 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc.arm_cpu', ('TENSOR', (1, 14, 14, 64), 'int16'), ('TENSOR', (1, 1, 1, 8, 256), 'uint8'), (1, 1), (0, 0, 0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc.arm_cpu', ('TENSOR', (1, 14, 14, 512), 'int16'), ('TENSOR', (1, 1, 1, 64, 64), 'uint8'), (1, 1), (0, 0, 0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc.arm_cpu', ('TENSOR', (1, 28, 28, 64), 'int16'), ('TENSOR', (1, 1, 1, 8, 256), 'uint8'), (1, 1), (0, 0, 0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc.arm_cpu', ('TENSOR', (1, 28, 28, 384), 'int16'), ('TENSOR', (1, 1, 1, 48, 64), 'uint8'), (1, 1), (0, 0, 0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc.arm_cpu', ('TENSOR', (1, 28, 28, 64), 'int16'), ('TENSOR', (1, 1, 1, 8, 192), 'uint8'), (1, 1), (0, 0, 0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc.arm_cpu', ('TENSOR', (1, 28, 28, 256), 'int16'), ('TENSOR', (1, 1, 1, 32, 64), 'uint8'), (1, 1), (0, 0, 0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc.arm_cpu', ('TENSOR', (1, 28, 28, 32), 'int16'), ('TENSOR', (1, 1, 1, 4, 128), 'uint8'), (1, 1), (0, 0, 0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc.arm_cpu', ('TENSOR', (1, 28, 28, 256), 'int16'), ('TENSOR', (1, 1, 1, 32, 32), 'uint8'), (1, 1), (0, 0, 0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc.arm_cpu', ('TENSOR', (1, 56, 56, 32), 'int16'), ('TENSOR', (1, 1, 1, 4, 128), 'uint8'), (1, 1), (0, 0, 0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc.arm_cpu', ('TENSOR', (1, 56, 56, 128), 'int16'), ('TENSOR', (1, 1, 1, 16, 32), 'uint8'), (1, 1), (0, 0, 0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc.arm_cpu', ('TENSOR', (1, 56, 56, 32), 'int16'), ('TENSOR', (1, 1, 1, 4, 64), 'uint8'), (1, 1), (0, 0, 0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc.arm_cpu', ('TENSOR', (1, 56, 56, 96), 'int16'), ('TENSOR', (1, 1, 1, 12, 32), 'uint8'), (1, 1), (0, 0, 0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc.arm_cpu', ('TENSOR', (1, 56, 56, 32), 'int16'), ('TENSOR', (3, 3, 1, 4, 64), 'uint8'), (1, 1), (1, 1, 1, 1), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc.arm_cpu', ('TENSOR', (1, 56, 56, 32), 'int16'), ('TENSOR', (3, 3, 1, 4, 128), 'uint8'), (1, 1), (1, 1, 1, 1), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc.arm_cpu', ('TENSOR', (1, 28, 28, 32), 'int16'), ('TENSOR', (3, 3, 1, 4, 128), 'uint8'), (1, 1), (1, 1, 1, 1), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc.arm_cpu', ('TENSOR', (1, 28, 28, 64), 'int16'), ('TENSOR', (3, 3, 1, 8, 192), 'uint8'), (1, 1), (1, 1, 1, 1), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc.arm_cpu', ('TENSOR', (1, 28, 28, 64), 'int16'), ('TENSOR', (3, 3, 1, 8, 256), 'uint8'), (1, 1), (1, 1, 1, 1), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc.arm_cpu', ('TENSOR', (1, 14, 14, 64), 'int16'), ('TENSOR', (3, 3, 1, 8, 256), 'uint8'), (1, 1), (1, 1, 1, 1), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n"
     ]
    }
   ],
   "source": [
    "with relay.build_config(opt_level=3):\n",
    "    graph, lib, params = relay.build(mod, target=target, params=params)\n",
    "    #out = intrp.evaluate(func)(np.random.uniform(size=(1, 3, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = util.tempdir()\n",
    "lib_fname = tmp.relpath('net.tar')\n",
    "lib.export_library(lib_fname)\n",
    "\n",
    "remote = autotvm.measure.request_remote(\n",
    "    'rasp4b', 'tracker', 9191, timeout=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the library to remote device and load it\n",
    "remote.upload(lib_fname)\n",
    "rlib = remote.load_module('net.tar')\n",
    "\n",
    "# create the remote runtime module\n",
    "ctx = remote.cpu(0)\n",
    "module = runtime.create(graph, rlib, ctx)\n",
    "# set parameter (upload params to the remote device. This may take a while)\n",
    "module.set_input(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n"
     ]
    }
   ],
   "source": [
    "#module.set_input(0, np.random.uniform(size=(1, 3, 224, 224)))\n",
    "module.set_input(0, np.random.uniform(size=(1, 224, 224, 3)))\n",
    "module.run()\n",
    "print(module.get_output(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate inference time cost...\n",
      "Mean inference time (std dev): 68.64 ms (0.00 ms)\n"
     ]
    }
   ],
   "source": [
    " # Evaluate\n",
    "print(\"Evaluate inference time cost...\")\n",
    "ftimer = module.module.time_evaluator(\"run\", ctx, number=10, repeat=1)\n",
    "prof_res = np.array(ftimer().results) * 1000  # Convert to milliseconds\n",
    "print(\"Mean inference time (std dev): %.2f ms (%.2f ms)\" %\n",
    "      (np.mean(prof_res), np.std(prof_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
