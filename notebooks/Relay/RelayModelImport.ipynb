{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tvm\n",
    "import tvm.relay as relay\n",
    "import tvm.contrib.graph_runtime as runtime\n",
    "from tvm.relay.expr_functor import ExprMutator\n",
    "from tvm.contrib import util\n",
    "from tvm.contrib.util import tempdir\n",
    "import riptide.models\n",
    "from riptide.get_models import get_model\n",
    "from tvm import autotvm\n",
    "from riptide.binary.binary_layers import Config, DQuantize, XQuantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(actQ=DQuantize, weightQ=XQuantize, bits=1, use_act=False, use_bn=False, use_maxpool=True)\n",
    "#config = Config(actQ=None, weightQ=None, bits=None, use_act=True, use_bn=True, use_maxpool=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with config:\n",
    "    model = get_model('squeezenet')\n",
    "#model = riptide.models.vggnet_normal.vggnet()\n",
    "#model = tf.keras.models.Sequential(model.layers[:30])\n",
    "#model = tf.keras.models.Sequential()\n",
    "#model.add(tf.keras.layers.Conv2D(filters=96, strides=2, padding='same', kernel_size=7, use_bias=False, data_format='channels_last'))\n",
    "#model.add(tf.keras.layers.BatchNormalization(center=False, scale=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = tf.keras.Input(shape=[224, 224, 3], batch_size=1, dtype='float32')\n",
    "output = model(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_ops = 0\n",
    "glue_ops = 0\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if 'conv2d' in layer.name:\n",
    "        _, h, w, f = layer.output_shape\n",
    "        k, _, c, _ = layer.weights[0].shape\n",
    "        #print(\"conv: \", k*k*h*w*f*c)\n",
    "        #print(\"glue: \", 14*h*w*f)\n",
    "        #print(\"ratio: \", k*k*c / 14)\n",
    "        conv_ops += k*k*h*w*f*c\n",
    "        glue_ops += 14 * h*w*f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786057216\n",
      "51806720\n",
      "15.172881355932203\n"
     ]
    }
   ],
   "source": [
    "print(conv_ops)\n",
    "print(glue_ops)\n",
    "print(conv_ops / glue_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"squeeze_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (1, 112, 112, 96)         14208     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (1, 112, 112, 96)         384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (1, 56, 56, 96)           0         \n",
      "_________________________________________________________________\n",
      "enter_integer (EnterInteger) (1, 56, 56, 96)           0         \n",
      "_________________________________________________________________\n",
      "binary_conv2d (BinaryConv2D) (1, 56, 56, 16)           1536      \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm (UnfusedB (1, 56, 56, 16)           64        \n",
      "_________________________________________________________________\n",
      "binary_conv2d_1 (BinaryConv2 (1, 56, 56, 64)           1024      \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_1 (Unfuse (1, 56, 56, 64)           256       \n",
      "_________________________________________________________________\n",
      "binary_conv2d_2 (BinaryConv2 (1, 56, 56, 64)           9216      \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_2 (Unfuse (1, 56, 56, 64)           256       \n",
      "_________________________________________________________________\n",
      "concatenate (Concatenate)    (1, 56, 56, 128)          0         \n",
      "_________________________________________________________________\n",
      "binary_conv2d_3 (BinaryConv2 (1, 56, 56, 16)           2048      \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_3 (Unfuse (1, 56, 56, 16)           64        \n",
      "_________________________________________________________________\n",
      "binary_conv2d_4 (BinaryConv2 (1, 56, 56, 64)           1024      \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_4 (Unfuse (1, 56, 56, 64)           256       \n",
      "_________________________________________________________________\n",
      "binary_conv2d_5 (BinaryConv2 (1, 56, 56, 64)           9216      \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_5 (Unfuse (1, 56, 56, 64)           256       \n",
      "_________________________________________________________________\n",
      "concatenate_1 (Concatenate)  (1, 56, 56, 128)          0         \n",
      "_________________________________________________________________\n",
      "binary_conv2d_6 (BinaryConv2 (1, 56, 56, 32)           4096      \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_6 (Unfuse (1, 56, 56, 32)           128       \n",
      "_________________________________________________________________\n",
      "binary_conv2d_7 (BinaryConv2 (1, 56, 56, 128)          4096      \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_7 (Unfuse (1, 56, 56, 128)          512       \n",
      "_________________________________________________________________\n",
      "binary_conv2d_8 (BinaryConv2 (1, 56, 56, 128)          36864     \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_8 (Unfuse (1, 56, 56, 128)          512       \n",
      "_________________________________________________________________\n",
      "concatenate_2 (Concatenate)  (1, 56, 56, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (1, 28, 28, 256)          0         \n",
      "_________________________________________________________________\n",
      "binary_conv2d_9 (BinaryConv2 (1, 28, 28, 32)           8192      \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_9 (Unfuse (1, 28, 28, 32)           128       \n",
      "_________________________________________________________________\n",
      "binary_conv2d_10 (BinaryConv (1, 28, 28, 128)          4096      \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_10 (Unfus (1, 28, 28, 128)          512       \n",
      "_________________________________________________________________\n",
      "binary_conv2d_11 (BinaryConv (1, 28, 28, 128)          36864     \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_11 (Unfus (1, 28, 28, 128)          512       \n",
      "_________________________________________________________________\n",
      "concatenate_3 (Concatenate)  (1, 28, 28, 256)          0         \n",
      "_________________________________________________________________\n",
      "binary_conv2d_12 (BinaryConv (1, 28, 28, 48)           12288     \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_12 (Unfus (1, 28, 28, 48)           192       \n",
      "_________________________________________________________________\n",
      "binary_conv2d_13 (BinaryConv (1, 28, 28, 192)          9216      \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_13 (Unfus (1, 28, 28, 192)          768       \n",
      "_________________________________________________________________\n",
      "binary_conv2d_14 (BinaryConv (1, 28, 28, 192)          82944     \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_14 (Unfus (1, 28, 28, 192)          768       \n",
      "_________________________________________________________________\n",
      "concatenate_4 (Concatenate)  (1, 28, 28, 384)          0         \n",
      "_________________________________________________________________\n",
      "binary_conv2d_15 (BinaryConv (1, 28, 28, 48)           18432     \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_15 (Unfus (1, 28, 28, 48)           192       \n",
      "_________________________________________________________________\n",
      "binary_conv2d_16 (BinaryConv (1, 28, 28, 192)          9216      \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_16 (Unfus (1, 28, 28, 192)          768       \n",
      "_________________________________________________________________\n",
      "binary_conv2d_17 (BinaryConv (1, 28, 28, 192)          82944     \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_17 (Unfus (1, 28, 28, 192)          768       \n",
      "_________________________________________________________________\n",
      "concatenate_5 (Concatenate)  (1, 28, 28, 384)          0         \n",
      "_________________________________________________________________\n",
      "binary_conv2d_18 (BinaryConv (1, 28, 28, 64)           24576     \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_18 (Unfus (1, 28, 28, 64)           256       \n",
      "_________________________________________________________________\n",
      "binary_conv2d_19 (BinaryConv (1, 28, 28, 256)          16384     \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_19 (Unfus (1, 28, 28, 256)          1024      \n",
      "_________________________________________________________________\n",
      "binary_conv2d_20 (BinaryConv (1, 28, 28, 256)          147456    \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_20 (Unfus (1, 28, 28, 256)          1024      \n",
      "_________________________________________________________________\n",
      "concatenate_6 (Concatenate)  (1, 28, 28, 512)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (1, 14, 14, 512)          0         \n",
      "_________________________________________________________________\n",
      "binary_conv2d_21 (BinaryConv (1, 14, 14, 64)           32768     \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_21 (Unfus (1, 14, 14, 64)           256       \n",
      "_________________________________________________________________\n",
      "binary_conv2d_22 (BinaryConv (1, 14, 14, 256)          16384     \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_22 (Unfus (1, 14, 14, 256)          1024      \n",
      "_________________________________________________________________\n",
      "binary_conv2d_23 (BinaryConv (1, 14, 14, 256)          147456    \n",
      "_________________________________________________________________\n",
      "unfused_batch_norm_23 (Unfus (1, 14, 14, 256)          1024      \n",
      "_________________________________________________________________\n",
      "concatenate_7 (Concatenate)  (1, 14, 14, 512)          0         \n",
      "_________________________________________________________________\n",
      "exit_integer (ExitInteger)   (1, 14, 14, 512)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (1, 512)                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (1, 1000)                 513000    \n",
      "=================================================================\n",
      "Total params: 1,257,448\n",
      "Trainable params: 1,251,496\n",
      "Non-trainable params: 5,952\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "func, params = relay.frontend.from_keras(model, shape={'input_1': [1, 224, 224, 3]}, layout='NHWC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tvm.target.arm_cpu(\"rasp3b\")\n",
    "target_host = 'llvm -device=arm_cpu -target=arm-linux-gnueabihf -mattr=+neon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0829 21:21:01.339347 139789975549760 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('dense', (1, 64, 'float32'), (1000, 64, 'float32'), 0, 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 21:21:01.352967 139789975549760 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 14, 14, 32, 'int16'), (1, 1, 1, 4, 32, 'uint8'), (1, 1), (0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 21:21:01.369346 139789975549760 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 14, 14, 96, 'int16'), (1, 1, 1, 12, 32, 'uint8'), (1, 1), (0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 21:21:01.390928 139789975549760 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 28, 28, 64, 'int16'), (1, 1, 1, 8, 48, 'uint8'), (1, 1), (0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 21:21:01.408473 139789975549760 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 28, 28, 128, 'int16'), (1, 1, 1, 16, 64, 'uint8'), (1, 1), (0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 21:21:01.427945 139789975549760 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 56, 56, 64, 'int16'), (1, 1, 1, 8, 64, 'uint8'), (1, 1), (0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 21:21:01.441816 139789975549760 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 56, 56, 96, 'int16'), (1, 1, 1, 12, 64, 'uint8'), (1, 1), (0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 21:21:01.462944 139789975549760 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 112, 112, 64, 'int16'), (1, 1, 1, 8, 48, 'uint8'), (1, 1), (0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 21:21:01.480296 139789975549760 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 112, 112, 64, 'int16'), (1, 1, 1, 8, 64, 'uint8'), (1, 1), (0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 21:21:01.499797 139789975549760 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 224, 224, 32, 'int16'), (1, 1, 1, 4, 32, 'uint8'), (1, 1), (0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 21:21:01.515448 139789975549760 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('conv2d', (1, 224, 224, 3, 'float32'), (3, 3, 3, 32, 'float32'), (1, 1), (1, 1), (1, 1), 'NHWC', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 21:21:01.524192 139789975549760 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 224, 224, 32, 'int16'), (3, 3, 1, 4, 32, 'uint8'), (1, 1), (1, 1), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 21:21:01.542762 139789975549760 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 112, 112, 64, 'int16'), (3, 3, 1, 8, 48, 'uint8'), (1, 1), (1, 1), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 21:21:01.559688 139789975549760 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 56, 56, 64, 'int16'), (3, 3, 1, 8, 64, 'uint8'), (1, 1), (1, 1), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 21:21:01.576472 139789975549760 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 28, 28, 64, 'int16'), (3, 3, 1, 8, 48, 'uint8'), (1, 1), (1, 1), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 21:21:01.593312 139789975549760 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 14, 14, 32, 'int16'), (3, 3, 1, 4, 32, 'uint8'), (1, 1), (1, 1), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n"
     ]
    }
   ],
   "source": [
    "with relay.build_config(opt_level=3):\n",
    "    graph, lib, params = relay.build(func, target=target, params=params)\n",
    "    #out = intrp.evaluate(func)(np.random.uniform(size=(1, 3, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = util.tempdir()\n",
    "lib_fname = tmp.relpath('net.tar')\n",
    "lib.export_library(lib_fname)\n",
    "\n",
    "remote = autotvm.measure.request_remote(\n",
    "    'rpi3b', 'fleet.cs.washington.edu', 9190, timeout=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the library to remote device and load it\n",
    "remote.upload(lib_fname)\n",
    "rlib = remote.load_module('net.tar')\n",
    "\n",
    "# create the remote runtime module\n",
    "ctx = remote.cpu(0)\n",
    "module = runtime.create(graph, rlib, ctx)\n",
    "# set parameter (upload params to the remote device. This may take a while)\n",
    "module.set_input(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n"
     ]
    }
   ],
   "source": [
    "#module.set_input(0, np.random.uniform(size=(1, 3, 224, 224)))\n",
    "module.set_input(0, np.random.uniform(size=(1, 224, 224, 3)))\n",
    "module.run()\n",
    "print(module.get_output(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate inference time cost...\n",
      "Mean inference time (std dev): 159.68 ms (0.00 ms)\n"
     ]
    }
   ],
   "source": [
    " # Evaluate\n",
    "print(\"Evaluate inference time cost...\")\n",
    "ftimer = module.module.time_evaluator(\"run\", ctx, number=10, repeat=1)\n",
    "prof_res = np.array(ftimer().results) * 1000  # Convert to milliseconds\n",
    "print(\"Mean inference time (std dev): %.2f ms (%.2f ms)\" %\n",
    "      (np.mean(prof_res), np.std(prof_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
