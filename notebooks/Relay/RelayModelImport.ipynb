{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tvm\n",
    "import tvm.relay as relay\n",
    "import tvm.contrib.graph_runtime as runtime\n",
    "from tvm.relay.expr_functor import ExprMutator\n",
    "from tvm.contrib import util\n",
    "from tvm.contrib.util import tempdir\n",
    "import riptide.models\n",
    "from riptide.get_models import get_model\n",
    "from tvm import autotvm\n",
    "from riptide.binary.binary_layers import Config, DQuantize, XQuantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(actQ=DQuantize, weightQ=XQuantize, bits=1, use_act=False, use_bn=False, use_maxpool=True)\n",
    "#config = Config(actQ=None, weightQ=None, bits=None, use_act=True, use_bn=True, use_maxpool=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with config:\n",
    "    model = get_model('squeezenet')\n",
    "#model = riptide.models.vggnet_normal.vggnet()\n",
    "#model = tf.keras.models.Sequential(model.layers[:30])\n",
    "#model = tf.keras.models.Sequential()\n",
    "#model.add(tf.keras.layers.Conv2D(filters=96, strides=2, padding='same', kernel_size=7, use_bias=False, data_format='channels_last'))\n",
    "#model.add(tf.keras.layers.BatchNormalization(center=False, scale=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0829 04:07:38.484236 140307224041280 deprecation.py:323] From /home/Riptide/riptide/binary/binary_layers.py:532: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "W0829 04:07:38.520052 140307224041280 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:279: calling Layer.add_update (from tensorflow.python.keras.engine.base_layer) with inputs is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`inputs` is now automatically inferred\n"
     ]
    }
   ],
   "source": [
    "test_input = tf.keras.Input(shape=[224, 224, 3], batch_size=1, dtype='float32')\n",
    "output = model(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "func, params = relay.frontend.from_keras(model, shape={'input_1': [1, 224, 224, 3]}, layout='NHWC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tvm.target.arm_cpu(\"rasp3b\")\n",
    "target_host = 'llvm -device=arm_cpu -target=arm-linux-gnueabihf -mattr=+neon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0829 04:07:42.830805 140307224041280 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('dense', (1, 64, 'float32'), (1000, 64, 'float32'), 0, 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 04:07:42.838276 140307224041280 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 14, 14, 32, 'int16'), (1, 1, 1, 4, 32, 'uint8'), (1, 1), (0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 04:07:42.854663 140307224041280 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 14, 14, 96, 'int16'), (1, 1, 1, 12, 32, 'uint8'), (1, 1), (0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 04:07:42.873703 140307224041280 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 28, 28, 64, 'int16'), (1, 1, 1, 8, 48, 'uint8'), (1, 1), (0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 04:07:42.888837 140307224041280 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 28, 28, 128, 'int16'), (1, 1, 1, 16, 64, 'uint8'), (1, 1), (0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 04:07:42.906946 140307224041280 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 56, 56, 64, 'int16'), (1, 1, 1, 8, 64, 'uint8'), (1, 1), (0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 04:07:42.922119 140307224041280 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 56, 56, 96, 'int16'), (1, 1, 1, 12, 64, 'uint8'), (1, 1), (0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 04:07:42.941485 140307224041280 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 112, 112, 64, 'int16'), (1, 1, 1, 8, 48, 'uint8'), (1, 1), (0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 04:07:42.956806 140307224041280 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 112, 112, 64, 'int16'), (1, 1, 1, 8, 64, 'uint8'), (1, 1), (0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 04:07:42.974313 140307224041280 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 224, 224, 32, 'int16'), (1, 1, 1, 4, 32, 'uint8'), (1, 1), (0, 0), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 04:07:42.990872 140307224041280 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('conv2d', (1, 224, 224, 3, 'float32'), (3, 3, 3, 32, 'float32'), (1, 1), (1, 1), (1, 1), 'NHWC', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 04:07:43.002800 140307224041280 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 224, 224, 32, 'int16'), (3, 3, 1, 4, 32, 'uint8'), (1, 1), (1, 1), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 04:07:43.029166 140307224041280 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 112, 112, 64, 'int16'), (3, 3, 1, 8, 48, 'uint8'), (1, 1), (1, 1), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 04:07:43.051666 140307224041280 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 56, 56, 64, 'int16'), (3, 3, 1, 8, 64, 'uint8'), (1, 1), (1, 1), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 04:07:43.074335 140307224041280 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 28, 28, 64, 'int16'), (3, 3, 1, 8, 48, 'uint8'), (1, 1), (1, 1), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0829 04:07:43.094762 140307224041280 dispatcher.py:381] Cannot find config for target=llvm -device=arm_cpu -model=bcm2837 -target=armv7l-linux-gnueabihf -mattr=+neon, workload=('bitserial_conv2d_nhwc', (1, 14, 14, 32, 'int16'), (3, 3, 1, 4, 32, 'uint8'), (1, 1), (1, 1), 1, 1, 'uint8', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n"
     ]
    }
   ],
   "source": [
    "with relay.build_config(opt_level=1):\n",
    "    graph, lib, params = relay.build(func, target=target, params=params)\n",
    "    #out = intrp.evaluate(func)(np.random.uniform(size=(1, 3, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = util.tempdir()\n",
    "lib_fname = tmp.relpath('net.tar')\n",
    "lib.export_library(lib_fname)\n",
    "\n",
    "remote = autotvm.measure.request_remote(\n",
    "    'rpi3b', 'fleet.cs.washington.edu', 9190, timeout=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the library to remote device and load it\n",
    "remote.upload(lib_fname)\n",
    "rlib = remote.load_module('net.tar')\n",
    "\n",
    "# create the remote runtime module\n",
    "ctx = remote.cpu(0)\n",
    "module = runtime.create(graph, rlib, ctx)\n",
    "# set parameter (upload params to the remote device. This may take a while)\n",
    "module.set_input(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n"
     ]
    }
   ],
   "source": [
    "#module.set_input(0, np.random.uniform(size=(1, 3, 224, 224)))\n",
    "module.set_input(0, np.random.uniform(size=(1, 224, 224, 3)))\n",
    "module.run()\n",
    "print(module.get_output(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate inference time cost...\n",
      "Mean inference time (std dev): 91.82 ms (0.00 ms)\n"
     ]
    }
   ],
   "source": [
    " # Evaluate\n",
    "print(\"Evaluate inference time cost...\")\n",
    "ftimer = module.module.time_evaluator(\"run\", ctx, number=10, repeat=1)\n",
    "prof_res = np.array(ftimer().results) * 1000  # Convert to milliseconds\n",
    "print(\"Mean inference time (std dev): %.2f ms (%.2f ms)\" %\n",
    "      (np.mean(prof_res), np.std(prof_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
