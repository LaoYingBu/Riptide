{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tvm\n",
    "import tvm.relay as relay\n",
    "import tvm.contrib.graph_runtime as runtime\n",
    "from tvm.relay.expr_functor import ExprMutator\n",
    "import riptide.models\n",
    "from riptide.get_models import get_model\n",
    "from riptide.binary.binary_layers import Config, DQuantize, XQuantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(actQ=DQuantize, weightQ=XQuantize, bits=1, use_act=False, use_bn=False, use_maxpool=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with config:\n",
    "#    model = get_model('vggnet')\n",
    "model = riptide.models.vggnet_normal.vggnet()\n",
    "#model = tf.keras.models.Sequential()\n",
    "#model.add(tf.keras.layers.Conv2D(filters=96, strides=2, padding='same', kernel_size=7, use_bias=False, data_format='channels_last'))\n",
    "#model.add(tf.keras.layers.BatchNormalization(center=False, scale=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = tf.keras.Input(shape=[224, 224, 3], batch_size=1, dtype='float32')\n",
    "output = model(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "func, params = relay.frontend.from_keras(model, shape={'input_1': [1, 224, 224, 3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0613 00:00:05.150222 140685900666688 dispatcher.py:381] Cannot find config for target=llvm, workload=('conv2d', (1, 3, 229, 229, 'float32'), (96, 3, 7, 7, 'float32'), (2, 2), (0, 0), (1, 1), 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "W0613 00:00:05.250350 140685900666688 dispatcher.py:381] Cannot find config for target=llvm, workload=('bitserial_dense', (1, 4096, 'int16'), (1000, 1, 128, 'uint32'), 1, 1, 'uint32', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0613 00:00:05.272911 140685900666688 dispatcher.py:381] Cannot find config for target=llvm, workload=('bitserial_dense', (1, 4096, 'int16'), (4096, 1, 128, 'uint32'), 1, 1, 'uint32', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0613 00:00:05.295073 140685900666688 dispatcher.py:381] Cannot find config for target=llvm, workload=('bitserial_dense', (1, 25088, 'int16'), (4096, 1, 784, 'uint32'), 1, 1, 'uint32', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0613 00:00:05.321627 140685900666688 dispatcher.py:381] Cannot find config for target=llvm, workload=('bitserial_conv2d_nchw', (1, 512, 14, 14, 'int16'), (1, 512, 16, 3, 3, 'uint32'), (1, 1), (1, 1), 1, 1, 'uint32', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0613 00:00:05.358666 140685900666688 dispatcher.py:381] Cannot find config for target=llvm, workload=('bitserial_conv2d_nchw', (1, 512, 28, 28, 'int16'), (1, 512, 16, 3, 3, 'uint32'), (1, 1), (1, 1), 1, 1, 'uint32', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0613 00:00:05.394706 140685900666688 dispatcher.py:381] Cannot find config for target=llvm, workload=('bitserial_conv2d_nchw', (1, 256, 28, 28, 'int16'), (1, 512, 8, 3, 3, 'uint32'), (1, 1), (1, 1), 1, 1, 'uint32', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0613 00:00:05.431313 140685900666688 dispatcher.py:381] Cannot find config for target=llvm, workload=('bitserial_conv2d_nchw', (1, 256, 56, 56, 'int16'), (1, 256, 8, 3, 3, 'uint32'), (1, 1), (1, 1), 1, 1, 'uint32', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n",
      "W0613 00:00:05.465352 140685900666688 dispatcher.py:381] Cannot find config for target=llvm, workload=('bitserial_conv2d_nchw', (1, 96, 56, 56, 'int16'), (1, 256, 3, 3, 3, 'uint32'), (1, 1), (1, 1), 1, 1, 'uint32', 'int16', 1). A fallback configuration is used, which may bring great performance regression.\n"
     ]
    }
   ],
   "source": [
    "with relay.build_config(opt_level=3):\n",
    "    #graph, lib, params = relay.build(func, 'llvm', params=params)\n",
    "    graph, lib, params = relay.build_module.build(func, target='llvm', params=params)\n",
    "    #out = intrp.evaluate(func)(np.random.uniform(size=(1, 3, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = runtime.create(graph, lib, tvm.context('llvm', 0))\n",
    "module.set_input(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n"
     ]
    }
   ],
   "source": [
    "module.set_input('input_1', np.random.uniform(size=(1, 3, 224, 224)))\n",
    "module.run()\n",
    "print(module.get_output(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate inference time cost...\n",
      "Mean inference time (std dev): 211.00 ms (12.63 ms)\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "ctx = tvm.cpu()\n",
    "print(\"Evaluate inference time cost...\")\n",
    "ftimer = module.module.time_evaluator(\"run\", ctx, number=1, repeat=100)\n",
    "prof_res = np.array(ftimer().results) * 1000  # convert to millisecond\n",
    "print(\"Mean inference time (std dev): %.2f ms (%.2f ms)\" %\n",
    "      (np.mean(prof_res), np.std(prof_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
