{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.ops import bitwise_ops\n",
    "from tensorflow.contrib import autograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32, shape=[4, 128])    \n",
    "b = tf.placeholder(tf.float32, shape=[128, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitwise_xnor(a, b):\n",
    "    # Need to do some dim expanding to handle batches.\n",
    "    a = tf.expand_dims(a, axis=1)\n",
    "    b = tf.expand_dims(b, axis=0)\n",
    "    ab = bitwise_ops.invert(bitwise_ops.bitwise_xor(a, b))\n",
    "    return ab\n",
    "\n",
    "def binarize_dense(x, transpose=False):\n",
    "    if transpose:\n",
    "        x = tf.transpose(x, [1,0])\n",
    "    h, w = x.shape\n",
    "    num_bins = int(w / 64)\n",
    "    binary_x = tf.cast(x > 0, tf.int64)\n",
    "    packed_x= []\n",
    "    for b in range(num_bins):\n",
    "        packed_x.append(tf.zeros(shape=[h], dtype=tf.int64))\n",
    "    for k in range(num_bins):\n",
    "        for b in range(64):\n",
    "            packed_x[k] = bitwise_ops.bitwise_or(packed_x[k], bitwise_ops.left_shift(binary_x[:, 64*k + b], b))\n",
    "    packed_x = tf.stack(packed_x, axis=-1)     \n",
    "    return packed_x\n",
    "\n",
    "def binarize_dense_fast(x, transpose=False):\n",
    "    if transpose:\n",
    "        x = tf.transpose(x, [1,0])\n",
    "    h, w = x.shape\n",
    "    num_bins = int(w / 64)\n",
    "    # Create shift tensor and apply it to binarized input.\n",
    "    shift_bits = tf.broadcast_to(tf.range(64, dtype=tf.int64), x.shape)\n",
    "    binary_x = tf.cast(x > 0, tf.int64)\n",
    "    binary_x = bitwise_ops.left_shift(binary_x, shift_bits)\n",
    "    # Split binarized x into chunks.\n",
    "    binary_chunks = tf.split(binary_x, num_bins, axis=-1)\n",
    "    # Combine chunks using bitwise or (equivalent to reduce sum).\n",
    "    packed_x = tf.reduce_sum(binary_chunks, axis=-1)\n",
    "    packed_x = tf.transpose(packed_x, [1,0])\n",
    "    return packed_x\n",
    "    \n",
    "def binary_dense_matmul(a, b):\n",
    "    ab = bitwise_xnor(a, b)\n",
    "    pcnt = 2*(tf.cast(bitwise_ops.population_count(ab), tf.float32)) - 64\n",
    "    inner_sum = tf.reduce_sum(pcnt, axis=-1)\n",
    "    return inner_sum\n",
    "\n",
    "def binary_dense(a, b, binarize_a=True, binarize_b=False):\n",
    "    if binarize_a:\n",
    "        bin_a = binarize_dense_fast(a)\n",
    "    else:\n",
    "        bin_a = a\n",
    "    if binarize_b:\n",
    "        bin_b = binarize_dense_fast(b, transpose=True)\n",
    "    else:\n",
    "        bin_b = tf.transpose(b, [1,0])\n",
    "    return binary_dense_matmul(bin_a, bin_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_ab = binary_dense(a, b, binarize_b=True)\n",
    "ab_reg = tf.matmul(tf.sign(a), tf.sign(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_np = np.random.normal(size=a.shape.as_list())\n",
    "b_np = np.random.normal(size=b.shape.as_list())\n",
    "\n",
    "sess = tf.Session()\n",
    "ab_out, bin_ab_out = sess.run([ab_reg, bin_ab], feed_dict={a:a_np, b:b_np})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -28., -12.,   0.,  18.,   8.,  -8., -14.,   8., -22.,   8.,\n",
       "         -6.,   2.,  16., -16., -10.,   0., -12.,  -4.,   2., -10.,  -6.,\n",
       "         -6.,   4., -16.,  -6.,   2.,  -6.,  18.,  -4.,  14.,  -4.,   0.,\n",
       "          0.,  10.,  -2.,  18.,   0.,  -6.,  20.,  12.,  16.,  20., -24.,\n",
       "          6.,   8.,   8.,   6.,  -2.,   4.,  -4.,  16.,   8.,   2.,   2.,\n",
       "        -22.,  -2.,  10., -10., -10.,  -6.,   4.,  -8.,   0., -10.,  10.,\n",
       "          0.,  -4.,  -6.,  34., -18., -10.,   0.,  20.,   8., -24.,  10.,\n",
       "        -20.,  14.,  12.,  -4.,  -2.,   0., -18., -14.,  10.,  -4.,  12.,\n",
       "          6.,   8.,  20., -16.,   0.,  16.,   6.,   8.,   0.,   6.,   4.,\n",
       "        -16., -14.,   4., -16., -20.,  -4.,   2.,   0.,   6.,  -6.,   4.,\n",
       "          2., -10.,  12.,  10.,  10., -12.,  -2.,   0.,  14.,  12.,   4.,\n",
       "          2.,  14., -10.,   4., -10.,  26., -10.],\n",
       "       [  0., -20.,  -8.,   0., -14.,   8.,  -4.,  10.,   0.,  -6.,   4.,\n",
       "          6.,  10.,  -4.,   0.,  18.,   8.,   8.,  -8.,  -6., -18.,   6.,\n",
       "         -6.,   0.,  12., -18., -22.,  -2., -26.,  24.,  -6.,  -8.,   0.,\n",
       "         -4.,   2.,  10.,   2.,   4., -10.,  -4.,  16.,  12.,  -8.,  16.,\n",
       "        -10.,  16.,  -4.,  10.,  26.,  -8.,   0.,  12.,  -4.,  10.,  10.,\n",
       "          6.,   6.,  -6.,  10.,  10.,  14.,  -4., -12.,   4.,  10.,  -6.,\n",
       "          0.,  -8., -14.,  10.,  -2.,  -6.,   4.,   0.,  28.,   8., -14.,\n",
       "          0.,  22.,   0.,  20.,   2.,   4.,  10.,  34.,   2.,   8., -16.,\n",
       "         14.,  -4.,  -8., -16.,   8.,   8.,  10.,  -8.,   8.,   6.,  -4.,\n",
       "         -4.,  -6.,   0.,   0.,   4.,  12., -22.,   0.,  10.,  14.,   0.,\n",
       "        -14.,  10., -12., -10.,   2.,  -8.,  -2.,  12.,   6.,  20., -16.,\n",
       "         -6.,  -2.,   2.,  -4.,  18.,  -2., -10.],\n",
       "       [-14., -22.,  10.,   6.,  16.,  -2.,  -2.,   0.,  -6.,  -8.,  30.,\n",
       "          8.,  -4.,  14., -22.,   4.,  10.,   6.,  22.,  -4., -12.,  16.,\n",
       "          0.,   2.,  -6., -16., -16.,  12.,  12.,  14.,   0., -34., -26.,\n",
       "        -10.,  12.,   4., -12.,  14.,   4.,  -6.,  -2.,  -2.,   6.,  10.,\n",
       "         12.,  -2.,   2.,   4.,   8.,   6., -14.,  -2.,   2., -24.,  12.,\n",
       "         -8.,  -4.,  -4.,  -8.,   8.,   0.,  -6., -10.,  -6.,   0.,  -8.,\n",
       "         10.,  -6.,   8.,   8.,  12., -12., -18.,  22.,  18.,  -6.,   0.,\n",
       "          6.,  -4.,  18.,  14., -12., -18.,   8.,  12.,  -4., -14., -18.,\n",
       "          0.,  14.,  -2.,  -6.,  -2.,   6.,  24.,  18.,  10.,  12.,   2.,\n",
       "         10.,  20.,   2.,  -2.,  18.,  14., -36., -10.,  12., -20.,  -2.,\n",
       "         -4.,   8.,  34.,  -4., -16.,  -6.,   8.,   2.,   8.,  26.,  -6.,\n",
       "          0.,   4.,  -4.,  -6.,  -4.,   0.,  -4.],\n",
       "       [ -4.,  -4.,   8.,  -4., -18.,   4.,   8.,   2.,   4.,  18.,   0.,\n",
       "         -6.,   6.,   8.,  12.,  -6.,  16.,  20., -16.,   2., -22.,   2.,\n",
       "          2., -12., -16., -10.,  10.,  10.,   2.,   4.,  18.,   4.,  -8.,\n",
       "        -12., -10.,  18.,  10.,  -4.,   6.,   0.,   0.,  -8., -12.,  12.,\n",
       "          6.,  -4.,   4.,  14.,  -6.,   4.,   0.,   0.,  12.,  10.,  10.,\n",
       "         14.,  10., -14., -14.,   2.,   2.,  -4., -12.,  -8., -14.,  -6.,\n",
       "         12.,   0.,   2.,   6.,  10.,  -6.,  20.,  12.,  -8.,   4., -10.,\n",
       "          0.,   2.,   8.,  -8.,  -2.,  -4.,  -2., -10., -10.,  -8.,  -4.,\n",
       "          2.,   4.,   8.,   8.,   4.,   0.,   6., -16.,   8., -10.,  16.,\n",
       "         16.,  -6.,   0.,   0.,   4.,  12.,   2.,  -4.,  -2.,   2.,   0.,\n",
       "         -2.,   6.,  12.,  -6.,  -2.,   8.,   2.,  12., -26., -12.,  -8.,\n",
       "          2.,  -6.,   2.,   4.,   2.,  10.,  10.]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_ab_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -28., -12.,   0.,  18.,   8.,  -8., -14.,   8., -22.,   8.,\n",
       "         -6.,   2.,  16., -16., -10.,   0., -12.,  -4.,   2., -10.,  -6.,\n",
       "         -6.,   4., -16.,  -6.,   2.,  -6.,  18.,  -4.,  14.,  -4.,   0.,\n",
       "          0.,  10.,  -2.,  18.,   0.,  -6.,  20.,  12.,  16.,  20., -24.,\n",
       "          6.,   8.,   8.,   6.,  -2.,   4.,  -4.,  16.,   8.,   2.,   2.,\n",
       "        -22.,  -2.,  10., -10., -10.,  -6.,   4.,  -8.,   0., -10.,  10.,\n",
       "          0.,  -4.,  -6.,  34., -18., -10.,   0.,  20.,   8., -24.,  10.,\n",
       "        -20.,  14.,  12.,  -4.,  -2.,   0., -18., -14.,  10.,  -4.,  12.,\n",
       "          6.,   8.,  20., -16.,   0.,  16.,   6.,   8.,   0.,   6.,   4.,\n",
       "        -16., -14.,   4., -16., -20.,  -4.,   2.,   0.,   6.,  -6.,   4.,\n",
       "          2., -10.,  12.,  10.,  10., -12.,  -2.,   0.,  14.,  12.,   4.,\n",
       "          2.,  14., -10.,   4., -10.,  26., -10.],\n",
       "       [  0., -20.,  -8.,   0., -14.,   8.,  -4.,  10.,   0.,  -6.,   4.,\n",
       "          6.,  10.,  -4.,   0.,  18.,   8.,   8.,  -8.,  -6., -18.,   6.,\n",
       "         -6.,   0.,  12., -18., -22.,  -2., -26.,  24.,  -6.,  -8.,   0.,\n",
       "         -4.,   2.,  10.,   2.,   4., -10.,  -4.,  16.,  12.,  -8.,  16.,\n",
       "        -10.,  16.,  -4.,  10.,  26.,  -8.,   0.,  12.,  -4.,  10.,  10.,\n",
       "          6.,   6.,  -6.,  10.,  10.,  14.,  -4., -12.,   4.,  10.,  -6.,\n",
       "          0.,  -8., -14.,  10.,  -2.,  -6.,   4.,   0.,  28.,   8., -14.,\n",
       "          0.,  22.,   0.,  20.,   2.,   4.,  10.,  34.,   2.,   8., -16.,\n",
       "         14.,  -4.,  -8., -16.,   8.,   8.,  10.,  -8.,   8.,   6.,  -4.,\n",
       "         -4.,  -6.,   0.,   0.,   4.,  12., -22.,   0.,  10.,  14.,   0.,\n",
       "        -14.,  10., -12., -10.,   2.,  -8.,  -2.,  12.,   6.,  20., -16.,\n",
       "         -6.,  -2.,   2.,  -4.,  18.,  -2., -10.],\n",
       "       [-14., -22.,  10.,   6.,  16.,  -2.,  -2.,   0.,  -6.,  -8.,  30.,\n",
       "          8.,  -4.,  14., -22.,   4.,  10.,   6.,  22.,  -4., -12.,  16.,\n",
       "          0.,   2.,  -6., -16., -16.,  12.,  12.,  14.,   0., -34., -26.,\n",
       "        -10.,  12.,   4., -12.,  14.,   4.,  -6.,  -2.,  -2.,   6.,  10.,\n",
       "         12.,  -2.,   2.,   4.,   8.,   6., -14.,  -2.,   2., -24.,  12.,\n",
       "         -8.,  -4.,  -4.,  -8.,   8.,   0.,  -6., -10.,  -6.,   0.,  -8.,\n",
       "         10.,  -6.,   8.,   8.,  12., -12., -18.,  22.,  18.,  -6.,   0.,\n",
       "          6.,  -4.,  18.,  14., -12., -18.,   8.,  12.,  -4., -14., -18.,\n",
       "          0.,  14.,  -2.,  -6.,  -2.,   6.,  24.,  18.,  10.,  12.,   2.,\n",
       "         10.,  20.,   2.,  -2.,  18.,  14., -36., -10.,  12., -20.,  -2.,\n",
       "         -4.,   8.,  34.,  -4., -16.,  -6.,   8.,   2.,   8.,  26.,  -6.,\n",
       "          0.,   4.,  -4.,  -6.,  -4.,   0.,  -4.],\n",
       "       [ -4.,  -4.,   8.,  -4., -18.,   4.,   8.,   2.,   4.,  18.,   0.,\n",
       "         -6.,   6.,   8.,  12.,  -6.,  16.,  20., -16.,   2., -22.,   2.,\n",
       "          2., -12., -16., -10.,  10.,  10.,   2.,   4.,  18.,   4.,  -8.,\n",
       "        -12., -10.,  18.,  10.,  -4.,   6.,   0.,   0.,  -8., -12.,  12.,\n",
       "          6.,  -4.,   4.,  14.,  -6.,   4.,   0.,   0.,  12.,  10.,  10.,\n",
       "         14.,  10., -14., -14.,   2.,   2.,  -4., -12.,  -8., -14.,  -6.,\n",
       "         12.,   0.,   2.,   6.,  10.,  -6.,  20.,  12.,  -8.,   4., -10.,\n",
       "          0.,   2.,   8.,  -8.,  -2.,  -4.,  -2., -10., -10.,  -8.,  -4.,\n",
       "          2.,   4.,   8.,   8.,   4.,   0.,   6., -16.,   8., -10.,  16.,\n",
       "         16.,  -6.,   0.,   0.,   4.,  12.,   2.,  -4.,  -2.,   2.,   0.,\n",
       "         -2.,   6.,  12.,  -6.,  -2.,   8.,   2.,  12., -26., -12.,  -8.,\n",
       "          2.,  -6.,   2.,   4.,   2.,  10.,  10.]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
